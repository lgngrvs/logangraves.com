# Wrong but useful models
Date: 2025-08-24
Tags: snippets
Type: page
Desc: 

*Posted 2024-07-19. Updated 2025-08-24.*

*Similar idea: the tradeoff between precision and usefulness*

**The crux:** ways of thinking about the world don't always have to be exactly right to be highly useful; things can be wrong and very interesting.

Sometimes it's okay to be incorrect about things, since "having exactly correct beliefs about how the world works" is not the only goal that ~~a person~~ an agent pursues.

## Heuristics
For example, using heuristic models of the world for inconsequential decisions allows you to focus your attention on things that are really important and expend cognitive effort on actions that bring you more value, even if that means that your inconsequential decisions will be wrong more often. 

Some simple examples of this might be "if the clouds look all dark and lumpy and big it's probably going to rain" or "if someone is yelling aggressively at you, they are mad at you." These will not always be true. Sometimes the clouds won't rain on you. Sometimes the person will just be really trying to convey important information in a noisy environment. Generally, though, these oversimplified models of the world are helpful for you. 


## Correct predictions, incorrect explanations
Some simple models might be based on highly load-bearing ideological systems that make them *totally wrong* in their explanations but *correct* in their predictions. For a quick example that I just made up, imagine a seafaring people who hold lemons to be holy; they might use this citrus in a consistent ritual when at sea, helping prevent scurvy; their explanation of why they don't get scurvy and others do might be that "the gods are curing us through our consumption of their divine essence and driving out the demon spirits which cause disease" which might be kinda true if you stretch that reaaaaalllly far as a metaphor, but really the most 'accurate' explanation (i.e. the one which is incorporated into a theory which is more systematically predictive) is ~~way more mundane than~~ really *different* from that. Either way, their prediction (they will get less scurvy if they consume the holy fruit) is correct, but their explanation (holy fruit is divine and as such protects the body from demons). **This is often how I think about tradition: often-good ideas, useful heuristics, etc., embedded in systems that perpetuate them. But these systems might lose the 'truth' of why they work.** 

*Added 2024-08-24:* Re-reading this section, I'm noticing that it's dancing around the ancient problem in epistemology of what it means to 'know': commonly it's described as 'justified true belief' but there's a whole class of [Gettier problems](https://en.wikipedia.org/wiki/Gettier_problem) that seem to indicate that that definition doesn't match our intuition of what knowledge is. (Notice how [Knowledge - Wikipedia](https://en.wikipedia.org/wiki/Knowledge) handles it. See also [IEP's entry on knowledge](https://iep.utm.edu/knowledg/#H5) particularly section 5 which the link will take you to.)


## Wrong models as starting points for refinement
If you're *trying* to be more correct about the world, simple heuristics might also be helpful as stepping-stones for finding more accurate models. *Hmm, why do those clouds that are all dark and lumpy seem to rain more?* That question can be a starting point for a budding meteorologist's investigations. Then one can build on the idea: *well, darkness and lumpiness seem to predict rain — darkness implies less light gets through. if clouds are made of water, maybe that means there's more water in the cloud, scattering more light... so maybe the more water that is in a cloud, the more likely it is to rain.* Your heuristic picks out a trend in experience — in empirical data. So investigating or reasoning about the trend can help you get closer to how things work.

Sometimes more complex models of the world can provide *useful frames on experience*, giving you space to maneuver conceptually and base hypotheses to mess with, even if the models are fundamentally incorrect about how things work deep down. For example, Freud had complex psychological models. Karl Popper might tell you that his models don't make meaningful predictions about human behavior as a whole — it's not really *science,* it has no *predictive validity,* and in a sense no claim to truth — and yet thinking about my motivation in the sense of, say, the mediation between id, ego, and superego, can point me to useful insights about myself. For example, I might frame something I'm conflicted about as a dialogue between superego and id — to speak very roughly, "my sense of morality" and "my unmediated, fundamental desires" — which can help me recognize things about myself. Or, perhaps, by thinking about the distinction between "want" (id) and "should" (superego), I might recognize that there are some things that I *want to want to do* but actually do not really care about — second-order wants. For example, I might *want to want* to get better at some specific kind of math, but not actually be interested in it. This is a meaningful distinction that has helped me adjust my behavior.

For an example of another model that one might continue developing:

> There are four things people confuse all the time, and use the same sort of language to express, despite them meaning very different things:
> 
> 1) I want to do X.
> 
> 2) I want X to be done, but don’t want to do it.
> 
> 3) I want to be the sort of person who does or can do X.
> 
> 4) I want to be seen as the sort of person who does or can do X.
> 
> -*from [Daystar Eld](https://daystareld.com/executive-function-1/) (though note that this model was probably not something he came up with by studying Freud)*

Sometimes you can even use a model as a ladder to some higher insight, and then discard the ladder entirely once you've climbed the wall. 

## The ladder in the *Tractatus*

*The following example is going to be the least clear of anything on this page, sorry; if you haven't read the work I'm referencing, feel free to ignore the technical details and just skim parts you don't understand. Also, if you think we are treading similar intellectual paths and you haven't read the [Tractatus](/tractatus), I would even say skip this entire example and just go read the book. It's probably one of the few books of philosophy which one can meaningfully "spoil" by giving details of the "plot."*

Ludwig Wittgenstein's *Tractatus Logico-philosophicus* describes his "picture theory of language," a model of meaning in language wherein only sentences whose content describes (or rather reflects, "pictures") logical relations of objects in the world are meaningful, and everything else is in a sense *meaningless*. 

The precise content of the *Tractatus*' theory of language doesn't matter that much, and in fact I don't remember much of it (lol); what did matter to me was how it served as a ladder for me to recognize, or at least make explicit in my mind from previous passing thoughts, various important ideas: 

- Complex philosophical systems may be obscuring the fact that they're not actually talking about anything at all — anything that *exists* in a meaningful sense. 
- Ethics and epistemology are ~entirely different domains. 
- Logical and mystical ways of thinking are fully distinct — they aren't incompatible, they are simply *entirely separate modes of thought*. Puzzling over the logic of ineffable beauty that you experience is , uh, incoherent.
- Ethics and aesthetics are the same thing.

Hopefully these ideas mean something to you, and you can see why they might be useful as higher realizations outside the context of philosophy of language. In any case, I think the picture theory of language is very wrong (or at least highly incomplete); Wittgenstein himself later in his career seemed to change course in his ideas entirely, and by the writing of *Philosophical Investigations* held views about language that were essentially *antithetical* to those he seemed to express in the *Tractatus*.

The *Tractatus* helped me recognize other things that just aren't currently coming to mind immediately; it might well be the book (if you can call it a book) that has had the most significant impact on my thought. Wittgenstein in fact seems to have *intended* this ladder-like, use-and-discard method; though the precise details are not clear to me as to what exactly he intended for the realization to be. 

(I won't quote it to avoid spoilers, but the ladder is explicitly a metaphor he used.)

## Living with wrong-but-useful models

Sometimes wrong-but-useful models are all we have. That's kind of what science[^1] is doing, isn't it? It's just progress from wrong-but-useful models to less-wrong-and-more-useful models of the world.

I think about consciousness this way: there are lots of ways to think about it, and we have lots of models and theories and all of them are probably wrong but some of them might be useful for some object-level purposes like noticing things about your own perception and distinguishing qualia.

I think about living this way: there's no systematic theory of living life well; all we can do is create wrong-but-useful models of it, and learn from our experience how to live better — update towards less-wrong-and-more-useful models of the world.

## Interfaces and models (2025 update)

I had a conversation with someone recently who had spent a lot (like, a lot) of time on both mathematical/formal models *and* on qualitative models like those of 20th century continental philosophy. I've been confused particularly about French Theory for a while — people like Deleuze and Guattari, Foucault, Baudrillard, Lacan, and their contemporaries. I've been confused about what *value* they bring intellectually.

### WTF(rench theory)
In retrospect, Popper's emphasis on prediction and falsification has pretty thoroughly saturated my worldview — both because I liked what he wrote on it, and because people in the communities I spend time in like it a lot. (Prediction markets are pretty cool.) So looking at French Theory, at structuralism and post-structuralism, at critique, I just felt intrigued but *confused*: why do people — many people who on vibes seems to be pretty smart/tasteful — invest a huge amount of energy and study into grasping works filled with the kind of sprawling, onanistic, impenetrable prose that is characteristic of French Theory, if it doesn't even provide predictions? What kind of 'theory' is this? Obviously there is *something* going on, and of course falsifiable, systematic scientific orientation is not the only interesting or useful way to think about the world, but I couldn't tell from the outside whether it was a self-congratulatory echochamber with people who publish to feel good about themselves (like some corners of humanities academia today), a religion-like exegetical tradition (e.g. many people spend their lives studying scripture and debating the esoteric minutiae of e.g. what hyper-precise conditions make an animal slaughter kosher; French Theory and its continued study could be something like that?) ...

> R. Isaac son of R. Joseph further said in the name of R. Johanan: If the [muscular covering of the] gizzard was pierced but the inner lining was intact, it is permitted. The question was raised: What is the law if the inner lining was pierced but the muscular covering was intact? — Come and hear: R. Nahman taught: If one [coat of the gizzard] was pierced but not the other, it is permitted. Rabbah said: The gullet has two coats, the outer red and the inner white; if one was perforated but not the other, it is permitted. Why was it necessary to state that the outer coat was red and the inner white? — To teach that if these coats interchanged, it is trefah. The question was raised: What is the law if both coats were pierced, one hole, however, not coinciding with the other? —

... or some other kind of thing that wouldn't be worth the investment — or some actually mysterious and intellectually fruitful kind of study I don't really get?

I asked about this: why do you study French Theory?

### The difference between an interface and a model
They replied with something along the lines of, *there's a difference between an interface and a model*. 

**Models** are systematic and predictive, describing how exactly a system will behave. But some systems are too complex to be fully modeled — for example, history. 

People have tried lots of theories of history; some Marxists I have met, for example, really really really like (their understanding of) historical materialism to the extent that they apply it to ~any question about the social world, any analysis of the course of history, and use it to make all of their predictions. Thinking through the lens of material conditions and class conflict is in fact quite useful to model some things (e.g. social change related to enclosure movements in england) and less useful for understanding other things (e.g. the protestant reformation or the holocaust).[^2]

Adopting a single explanatory methodology for history is (empirically) pretty bad for your ability to think with nuance about history, regardless of what that explanatory methodology is. The reason for this is that history is fucking complicated. Human decisions are fucking complicated. Sociology and economics and other social sciences  (and historical materialism) exist as sciences because we can still try and identify patterns in history, but none of these have any hope of providing systematic models of history. 

Physics is an example of a much simpler system which we can model. With physics we can come up with *models.* But for things like history, it's useful to lower our expectations and accept lower epistemological standards (and put much bigger error bars on our predictions); that's kind of all we have.

**Interfaces** are a little more nebulous — ways of engaging with history. They're context and goal-dependent, explicitly limited methodologies or 'ways of thinking' about something. They might not give you specific predictions, but they might show you possibilities for your own action. Useful for some things and not for others. Thus, I'd like historical materialism as an *interface* for history, but not as a *model*.

You can have something like an internal epistemological market: some phenomenon demands an explanation, and you look at it and see which tool tends to be useful. Pick that interface for the phenomenon and apply it and see what it gives you back. What kinds of predictions or avenues for action do they give you? 

How does the current development of AI look through a [technological deterministic](https://en.wikipedia.org/wiki/Technological_determinism) lens? An [intellectual-historical](https://en.wikipedia.org/wiki/Intellectual_history) lens? Through a historical-materialist lens? Through a Butlerian gender-as-performance lens?[^3]Through a, god forbid, mormon [millenarianist](https://en.wikipedia.org/wiki/Millenarianism) lens? Yeah, sorry, some interfaces are actually just *bad*. But there are lots of reasonably good interfaces (or at least *interesting* ones). Some of these tools will be more useful for some phenomena and some goals. (Feminist or gender theory is probably useless to you for analyzing social relationships if you think that the goal of civilization is the continued heterosexual reproduction of the species, unless you make some galaxy-brained argument about 'better gender theory in order to do better heterosexuality or something'[^4].)

This "internal interface market" means that you can have many interpretive frames on a thing and see which one is useful. Broader disciplines seem to have them as well. Some interface markets I can think of: 

- Schools of therapy
- Schools of economics
- Schools of psychology
- Political ideology
- Lenses of literary theory

But these schools might not always be in fact treated like interfaces, but *models* — that seems to be driving various discursive failures.

### French theory provides interfaces

Bringing this all back to the mystery of the value of French Theory: what I got from the answer my friend gave me was something like, "French Theory provides interfaces."

- The Structuralist interface is looking for the "[generators](<https://en.wikipedia.org/wiki/Generator_(mathematics)>)" of culture and trying to take an abstract structure-based view of societies
- Foucault provides a lens on history (particularly the history of discourse) that ties knowledge and power together, and then applies that interface to understanding a bunch of other things
- Deleuze and Guattari are doing complex systems theory or something but without the math and in the context of the slightly postmodernslopped abstruse writing french academia
- lacan does, like, something psychoanalysis-like or something idk but it's maybe useful in the way that freud as an interface for psychological dynamics might be useful

Et cetera in this vein.

You can debate the efficacy of different interfaces. Some interfaces are pretty bad, e.g. racism is an interface for understanding history *but not a very good one.* But I think this framing is interesting.

I haven't read much French theory since I had this conversation (it was very recent as of writing) but we'll see how this idea holds up. I wanted to post it because I thought it was interesting.

<p class="footnote-header">Footnotes</p>

[^1]: (Here I mean not the modern material institutional science that has a replication crisis and struggles with poor economic incentives but the idealized truth-seeking science)

[^2]: Historical materialism is obviously not a monolithic mode of analysis (it's not even necessarily Marxist) and I'm oversimplifying it for the purpose of illustration here. Also, I want to make clear that I think adopting a totalizing worldview is pretty common, and certainly not exclusive to Marxism; Marx and Engels both complained about people not understanding or misusing their theory. Marxism is just the totalizing ideology I've encountered the most in my life.

[^3]: I'm saying this in part because it's kind of funny and absurd, but I'm not even joking here — I think there is a limited but still possibly useful conversation about how AI development dynamics are affected by the gender roles that the people developing it and setting policy around it perform, especially in light of the fact that AI as an industry is so dominated by men and male CEOs. There's this book review I recently read that, while not exactly saying this, I think might give you a sense of what I'm thinking here: [REVIEW: The Hard Thing about Hard Things](https://www.thepsmiths.com/p/review-the-hard-thing-about-hard).

[^4]: I feel like I don't really have a good understanding of what I'm trying to say here, sorry if this doesn't really make sense.


